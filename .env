# Database Configuration
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=aiuser
MYSQL_PASSWORD=Gccloud@1489$
MYSQL_DATABASE=topic_clustering

#DUMP DATABASE Configuration
DUMP_DB_HOST=94.136.189.147
DUMP_DB_NAME=up_police_matrix
DUMP_DB_USER=gccloud
DUMP_DB_PASSWORD=Gccloud@1489$
DUMP_DB_PORT=3306
API_BASE_URL=http://localhost:8000


# Vector Database Configuration
CHROMA_PERSIST_DIR=./chroma_db_3
CHROMA_COLLECTION_NAME=topic_vector

# Model Configuration
EMBEDDING_MODEL_NAME=jinaai/jina-embeddings-v3
#"jinaai/jina-embeddings-v3"
#"BAAI/bge-m3"
#"jinaai/jina-embeddings-v4"

# ==================== JINA V4 SPECIFIC CONFIGURATION ====================
# Whether to load all v4 tasks at startup (memory intensive but best performance)
# Set to 'true' for production, 'false' for development/memory-constrained environments
EMBEDDING_LOAD_ALL_TASKS=false

# Primary tasks to load for v4 (comma-separated)
# Available tasks: retrieval,clustering,classification,text-matching
# Recommendation: Start with clustering and text-matching for your use case
EMBEDDING_PRIMARY_TASKS=retrieval,text-matching

MISTRAL_MODEL_NAME=dphn/Dolphin-Mistral-24B-Venice-Edition
#MISTRAL_MODEL_PATH=/Users/pankajkumar/.cache/huggingface/hub/models--mlx-community--Dolphin-Mistral-24B-Venice-Edition-4bit/snapshots/7674b37fe24022cf79e77d204fac5b9582b0dc40

#"mlx-community/Dolphin-Mistral-24B-Venice-Edition-4bit"
#"mlx-community/Dolphin-Mistral-24B-Venice-Edition-mlx-8Bit"
#"dphn/Dolphin-Mistral-24B-Venice-Edition"
#"mistralai/Mixtral-8x22B-Instruct-v0.1"
#"mistralai/Mixtral-8x7B-Instruct-v0.1"
#"mistralai/Mixtral-8x7B-v0.1"
#"mistralai/Mistral-Small-3.2-24B-Instruct-2506"
#"mistralai/Codestral-22B-v0.1" - Checked - Working with Full Precision - on LS40s-2
#"mistralai/Mistral-7B-Instruct-v0.3" - Only Extractig for NER and Giving Topic but are not So Good or Able to Extract Contextual Analysis
#"mistralai/Mistral-7B-v0.1" Checked - Only Extractig for NER and Not Giving Topic or Contextual Analysis
#"unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF" - Checked - Need Other Interference than the vLLM to Load - Need more Work
#"unsloth/Mistral-Small-3.2-24B-Instruct-2506-unsloth-bnb-4bit" - Was not Loaded by vLLM
#"unsloth/Mistral-Small-3.2-24B-Instruct-2506-FP8" - Need Other Interference than the vLLM to Load - Need more Work

# Processing Configuration
SIMILARITY_THRESHOLD=0.90
BATCH_SIZE=32
MAX_TOPIC_TITLE_WORDS=15

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Environment
ENVIRONMENT=development
DEBUG=false

# Logging
LOG_LEVEL=DEBUG
LOG_FILE=./logs/app.log

TOKENIZERS_PARALLELISM=false

#45.198.13.51

CUDA_DEVICE_ORDER=PCI_BUS_ID
CUDA_VISIBLE_DEVICES=0,1
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True